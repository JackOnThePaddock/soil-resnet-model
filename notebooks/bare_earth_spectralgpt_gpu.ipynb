{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Soil Bare Earth + SpectralGPT (Colab GPU)\n",
        "\n",
        "This notebook runs your pipeline on Colab:\n",
        "1. Load your `soil-resnet-model` repo.\n",
        "2. Install dependencies.\n",
        "3. Pull GA Barest Earth values for normalized training points.\n",
        "4. Train SpectralGPT embeddings on those bands.\n",
        "5. Save outputs to Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Enable GPU runtime\n",
        "\n",
        "In Colab: `Runtime -> Change runtime type -> T4/A100 GPU`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ---- Configure these paths ----\n",
        "USE_GIT_CLONE = True\n",
        "REPO_GIT_URL = \"https://github.com/JackOnThePaddock/soil-resnet-model.git\"\n",
        "DRIVE_REPO_DIR = \"/content/drive/MyDrive/soil-resnet-model\"\n",
        "PROJECT_DIR = \"/content/soil-resnet-model\"\n",
        "\n",
        "if os.path.exists(PROJECT_DIR):\n",
        "    shutil.rmtree(PROJECT_DIR)\n",
        "\n",
        "if USE_GIT_CLONE:\n",
        "    if not REPO_GIT_URL:\n",
        "        raise ValueError(\"Set REPO_GIT_URL or set USE_GIT_CLONE=False\")\n",
        "    subprocess.run([\"git\", \"clone\", REPO_GIT_URL, PROJECT_DIR], check=True)\n",
        "else:\n",
        "    if not os.path.exists(DRIVE_REPO_DIR):\n",
        "        raise FileNotFoundError(f\"Repo not found at {DRIVE_REPO_DIR}\")\n",
        "    shutil.copytree(DRIVE_REPO_DIR, PROJECT_DIR)\n",
        "\n",
        "os.chdir(PROJECT_DIR)\n",
        "print(\"Project:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install project and dependencies\n",
        "!pip -q install --upgrade pip\n",
        "!pip -q install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confirm GPU availability\n",
        "import torch\n",
        "print(\"Torch:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Configure inputs/outputs\n",
        "\n",
        "`features_normalized.csv` does not contain `lat/lon`, so this uses `features.csv` for coordinates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "NORMALIZED_CSV = \"data/processed/features_normalized.csv\"\n",
        "POINTS_CSV = \"data/processed/features.csv\"\n",
        "OUTPUT_CSV = \"data/processed/features_normalized_bareearth_sgpt.csv\"\n",
        "OUTPUT_EMBEDDINGS_CSV = \"data/processed/features_normalized_sgpt_embeddings.csv\"\n",
        "\n",
        "for p in [NORMALIZED_CSV, POINTS_CSV]:\n",
        "    if not os.path.exists(p):\n",
        "        raise FileNotFoundError(f\"Missing input: {p}\")\n",
        "print(\"Inputs OK\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run Bare Earth point sampling + SpectralGPT embeddings\n",
        "# Adjust workers if you see timeouts or request throttling.\n",
        "!python scripts/pull_bare_earth_embeddings.py   --normalized-csv {NORMALIZED_CSV}   --points-csv {POINTS_CSV}   --output-csv {OUTPUT_CSV}   --output-embeddings-csv {OUTPUT_EMBEDDINGS_CSV}   --workers 16   --timeout 120   --retries 3   --spectral-backend official_pretrained   --official-request-chunk-size 64   --spectral-dim 16   --output-official-raw-csv data/processed/features_normalized_sgpt_official_raw.csv   --seed 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick sanity check\n",
        "import pandas as pd\n",
        "\n",
        "fused = pd.read_csv(OUTPUT_CSV)\n",
        "emb = pd.read_csv(OUTPUT_EMBEDDINGS_CSV)\n",
        "\n",
        "print(\"Fused shape:\", fused.shape)\n",
        "print(\"Embeddings shape:\", emb.shape)\n",
        "print(\"Bare Earth columns:\", [c for c in fused.columns if c.startswith('be_')][:10])\n",
        "print(\"SGPT columns:\", [c for c in fused.columns if c.startswith('sgpt_')][:10])\n",
        "print(\"Missing rate (be_):\", fused[[c for c in fused.columns if c.startswith('be_')]].isna().mean().mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save outputs back to Drive\n",
        "OUT_DIR = \"/content/drive/MyDrive/soil-resnet-outputs\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "!cp {OUTPUT_CSV} {OUT_DIR}/\n",
        "!cp {OUTPUT_EMBEDDINGS_CSV} {OUT_DIR}/\n",
        "\n",
        "print(\"Saved to:\", OUT_DIR)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "bare_earth_spectralgpt_gpu.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}